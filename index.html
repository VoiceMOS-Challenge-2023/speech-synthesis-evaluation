<html>
<head>
<title>Speech Synthesis Evalaution Reading List</title>
</head>
</title>

<body>

<h2>Speech Synthesis Evaluation</h2>

<p>
We have written a review paper on subjective and evaluation of speech synthesis (TODO more info once it's published).  
This webpage contains links to the papers cited in our review, as well as other interesting and relevant papers we have found since then.
</p>

<b>Table of Contents</b>
<ul>
  <li>2. Listening tests</li>
  <ul>
    <li>2.1  1980s to early 1990s: intelligibility and comprehension</li>
    <li>2.2  Mid-1990s and 2000s: naturalness, intelligibility, and efforts to standardize</li>
    <li>2.3  2010s to the present: crowdsourcing, MOS, and critiques</li>
  </ul>
  <li>3. Automatic evaluation for synthetic speech</li>
  <ul>
    <li>3.1  Difficulties in automatic evaluation of synthetic speech</li>
    <li>3.2  Speech quality assessment metrics from telephony</li>
    <li>3.3  Models for evaluation of synthetic speech</li>
    <ul>
      <li>3.3.1  Early attempts at machine learning based synthetic speech quality prediction</li>
      <li>3.3.2  Neural network-based synthetic speech quality prediction</li>
      <li>3.3.3  Listener modeling in synthetic speech evaluation</li>
      <li>3.3.4  SSL-based approaches</li>
      <li>3.3.5  Unsupervised approaches for synthetic speech quality prediction</li>
      <li>3.3.6  Beyond predicting quality of synthesized speech</li>
      <li>3.3.7  Predicting rank order and pairwise preferences</li>
      <li>3.3.8  Learning from speech quality prediction in other domains</li>
    </ul>
  </ul>
    <li>4. The VoiceMOS Challenge 2022</li>
    <ul>
      <li>4.1  Data and tracks</li>
      <li>4.2  Baselines</li>
      <li>4.3  Team approaches</li>
    </ul>
    <li>5. The VoiceMOS Challenge 2023</li>
    <ul>
      <li>5.1  Data and tracks</li>
      <li>5.2  Baselines</li>
      <li>5.3  Team approaches</li>
    </ul>
    <li>6.  Future prospects and challenges</li>
    
</ul>



  <h3>2. Listening tests</h3>
    <h4>2.1  1980s to early 1990s: intelligibility and
      comprehension</h4>

<p>[1] R. Van Bezooijen and
  L. C. Pols, <a href="https://doi.org/10.1016/0167-6393(90)90002-Q">"Evaluating text-to-
speech systems: Some methodological aspects,"</a> <i>Speech
Communication,</i> vol. 9, no. 4, pp. 263-270, 1990.</p>

<p>[2] A. S. House, C. Williams, M. H. Hecker, and
  K. D. Kryter, <a href="https://doi.org/10.1121/1.2142744">"Psychoacoustic
    speech tests: A modified rhyme test,"</a> <i>The Journal of the Acoustical Society of America,</i> vol. 35, pp. 1899-1899, 1963.</p>

<p>[3] W. D. Voiers, <a href="">"Evaluating processed speech using the
diagnostic rhyme test,"</a> <i>Speech Technol.,</i> vol. 1, pp. 30-
  39, 1983.</p>

<p>[4] M. Spiegel, M. J. Altom, M. Macchi, and K. Wallace, <a href="https://www.isca-archive.org/sioa_1989/spiegel89_sioa.html">"A monosyllabic test corpus to evaluate the
intelligibility of synthesized and natural speech,"</a> in
<i>Proc. Speech Input/Output Assessment and Speech
Databases,</i> 1989, pp. Vol.2, 5-10. </p> 

<p>[5] U. Jekosch, <a href="https://www.isca-archive.org/sioa_1989/jekosch89_sioa.html">"The cluster-based rhyme test: a segmental synthesis test for open vocabulary,"</a> in <i>Proc. Speech
Input/Output Assessment and Speech Databases,</i> 1989,
pp. Vol.2, 15-18.</p>

<p>[6] J. P. van Santen, <a href="https://www.sciencedirect.com/science/article/pii/S0885230883710041">"Perceptual experiments for diagnostic testing of text-to-speech systems,"</a> <i>Computer
Speech & Language,</i> vol. 7, no. 1, pp. 49-100, 1993.</p>

<p>[7] M. Grice, <a href="https://www.isca-archive.org/sioa_1989/grice89_sioa.html">"Syntactic structures and lexicon requirements for semantically unpredictable sentences in a
number of languages,"</a> in <i>Proc. Speech Input/Output
Assessment and Speech Databases,</i> 1989, pp. Vol.2, 19-
22.</p>

<p>[8] D. Pisoni and S. Hunnicutt, <a href="https://ieeexplore.ieee.org/abstract/document/1170888">"Perceptual evaluation
of MITalk: The MIT unrestricted text-to-speech system,"</a> in <i>ICASSP '80. IEEE International Conference
on Acoustics, Speech, and Signal Processing,</i> vol. 5,
1980, pp. 572-575.</p>

<p>[9] <a href="https://www.itu.int/rec/T-REC-P.800-199608-I">"Methods for subjective determination of transmission
quality,"</a> in <i>ITU-T Rec. P.800.</i> International Telecommunication Union (ITU-R)., 1996.</p>

<p>[10] M. Goldstein, B. Lindstr&#246;m, and O. Till, <a href="https://www.isca-archive.org/icslp_1992/goldstein92b_icslp.html">"Some aspects on
  context and response range effects when assessing naturalness of Swedish sentences generated
by 4 synthesiser systems,"</a> in <i>Proc. 2nd International
Conference on Spoken Language Processing (ICSLP
1992),</i> 1992, pp. 1339-1342.</p>

<p>[11] M. Goldstein, <a href="https://doi.org/10.1016/0167-6393(94)00047-E">"Classification of methods used for
assessment of text-to-speech systems according to
the demands placed on the listener,"</a> <i>Speech Communication,</i> vol. 16, no. 3, pp. 225-244, 1995.</p>


    
    <h4>2.2  Mid-1990s and 2000s: naturalness, intelligibility, and efforts to standardize</h4>

<p>[12] <a href="https://www.itu.int/rec/T-REC-P.85-199406-I/en">"A method for subjective performance assessment of
the quality of speech voice output devices,"</a> in <i>ITU-T
Rec. P.85.</i> International Telecommunication Union
(ITU-R)., 1994.</p>

<p>[13] <a href="https://www.itu.int/rec/T-REC-P.80-199303-S">"Methods for subjective determination of transmission
quality,"</a> in <i>ITU-T Rec. P.80.</a> International Telecommunication Union (ITU-R)., 1993.</p>

<p>[14] C. Beno&#238;t, M. Grice, and V. Hazan, <a href="https://doi.org/10.1016/0167-6393(96)00026-X">"The SUS
test: A method for the assessment of text-to-
speech synthesis intelligibility using Semantically
Unpredictable Sentences,"</a> <i>Speech Communication,</i>
vol. 18, no. 4, pp. 381-392, 1996</p>

<p>[15] S. Itahashi, <a href="http://www.lrec-conf.org/proceedings/lrec2000/html/summary/77.htm">"Guidelines for Japanese speech synthesizer evaluation,"</a> in <i>Proceedings of the Second
International Conference on Language Resources and
Evaluation (LRECâ€™00),</i> M. Gavrilidou, G. Carayannis,
S. Markantonatou, S. Piperidis, and G. Stainhauer,
Eds. Athens, Greece: European Language Resources
Association (ELRA), May 2000. </p>

<p>[16] Y. V. Alvarez and
  M. Huckvale, <a href="https://www.isca-archive.org/icslp_2002/alvarez02_icslp.html">"The
    reliability of the ITU-T P.85 standard for the evaluation of
  text-to-speech systems,"</a> in <i>Proc. 7th International Conference
on Spoken Language Processing (ICSLP 2002),</i> 2002,
pp. 329-332.</p>

<p>[17] D. Sityaev, K. Knill, and T. Burrows, <a href="https://www.isca-archive.org/interspeech_2006/sityaev06_interspeech.html">"Comparison
of the ITU-T P.85 standard to other methods for the
evaluation of text-to-speech systems,"</a> in <i>Proc. Interspeech 2006,</i> 2006.</p>

<p>[18]  L. C. W. Pols and U. Jekosch, <a href="https://doi.org/10.1007/978-1-4612-1894-4_41"><i>A Structured
Way of Looking at the Performance of Text-to-Speech Systems.</i></a> New York, NY: Springer New
York, 1997, pp. 519-527</p>

<p>[19] A. W. Black and K. Tokuda, <a href="https://www.isca-archive.org/interspeech_2005/black05_interspeech.html">"The Blizzard Challenge - 2005: evaluating corpus-based speech synthesis on
common datasets,"</a> in <i>Proc. Interspeech 2005,</i> 2005,
pp. 77-80.</p>

<p>[20] N. Campbell, <a href="https://doi.org/10.1007/978-1-4020-5817-2_2"><i>Evaluation of Speech Synthesis.</i></i> Dordrecht: Springer Netherlands, 2007, pp.
29-64</p>

<p>[21] S. Zielinski, F. Rumsey, and S. Bech, <a href="http://www.aes.org/e-lib/browse.cfm?elib=14393">"On some biases
encountered in modern audio quality listening tests - a review,"</i> <i>Journal of the Audio Engineering Society,</i>
vol. 56, no. 6, pp. 427-451, 2008.</p>

    <h4>2.3  2010s to the present: crowdsourcing, MOS, and critiques</h4>

<p>[22] K. Tokuda, H. Zen, and A. W. Black, <a href="https://doi.org/10.1109/WSS.2002.1224415">"An HMM-based
speech synthesis system applied to English,"</a> in <i>IEEE Speech Synthesis Workshop.</i> IEEE Santa Monica,
2002, pp. 227-230.</p>

<p>[23] X. Wang, J. Yamagishi, M. Todisco, H. Delgado,
A. Nautsch, N. Evans, M. Sahidullah, V. Vestman, T. Kinnunen, K. A. Lee, L. Juvela, P. Alku,
Y.-H. Peng, H.-T. Hwang, Y. Tsao, H.-M. Wang,
S. L. Maguer, M. Becker, F. Henderson, R. Clark,
Y. Zhang, Q. Wang, Y. Jia, K. Onuma, K. Mushika,
T. Kaneda, Y. Jiang, L.-J. Liu, Y.-C. Wu, W.-C.
Huang, T. Toda, K. Tanaka, H. Kameoka, I. Steiner,
D. Matrouf, J.-F. Bonastre, A. Govender, S. Ronanki, J.-X. Zhang, and
  Z.-H. Ling, <a href="https://doi.org/10.1016/j.csl.2020.101114">"ASVspoof 2019:
A large-scale public database of synthesized, converted and replayed speech,"</a> <i>Computer Speech &
Language,</i> vol. 64, p. 101114, 2020. </p>

<p>[24]</p>

<p>[25]</p>

<p>[26]</p>

<p>[27]</p>

<p>[28]</p>

<p>[29]</p>

<p>[30]</p>

<p>[31]</p>

<p>[32]</p>

<p>[33]</p>

<p>[34]</p>

<p>[35]</p>

<p>[36]</p>

<p>[37]</p>

<p>[38]</p>

<p>[39]</p>

<p>[40]</p>

<p>[41]</p>

<p>[42]</p>

<p>[43]</p>
    
  <h3>3. Automatic evaluation for synthetic speech</h3>

<p>[44]</p>
  
    <h4>3.1  Difficulties in automatic evaluation of synthetic speech</h4>

    <h4>3.2  Speech quality assessment metrics from telephony</h4>

<p>[45]</p>

<p>[46]</p>

<p>[47]</p>

<p>[48]</p>

<p>[49]</p>

<p>[50]</p>

<p>[51]</p>

<p>[52]</p>

<p>[53]</p>

<p>[54]</p>

<p>[55]</p>

<p>[56]</p>

<p>[57]</p>

<p>[58]</p>

<p>[59]</p>

    
    <h4>3.3  Models for evaluation of synthetic speech</h4>

<p>[60]</p>

<p>[61]</p>

<p>[62]</p>

<p>[63]</p>
    
    
      <h5>3.3.1  Early attempts at machine learning based synthetic speech quality prediction</h5>

<p>[64]</p>

<p>[65]</p>

<p>[66]</p>

<p>[67]</p>

<p>[68]</p>


      <h5>3.3.2  Neural network-based synthetic speech quality prediction</h5>

<p>[69]</p>

<p>[70]</p>

<p>[71]</p>

<p>[72]</p>

<p>[73]</p>

<p>[74]</p>

<p>[75]</p>

<p>[76]</p>

<p>[77]</p>

<p>[78]</p>

<p>[79]</p>

      <h5>3.3.3  Listener modeling in synthetic speech evaluation</h5>

<p>[80]</p>

<p>[81]</p>

      <h5>3.3.4  SSL-based approaches</h5>

<p>[82]</p>

<p>[83]</p>

<p>[84]</p>

<p>[85]</p>

<p>[86]</p>

<p>[87]</p>

<p>[88]</p>

<p>[89]</p>

<p>[90]</p>

<p>[91]</p>

<p>[92]</p>

<p>[93]</p>

      <h5>3.3.5  Unsupervised approaches for synthetic speech quality prediction</h5>

<p>[94]</p>

<p>[95]</p>

<p>[96]</p>

<p>[97]</p>

<p>[98]</p>

<p>[99]</p>

      <h5>3.3.6  Beyond predicting quality of synthesized speech</h5>

<p>[100]</p>

<p>[101]</p>

<p>[102]</p>

<p>[103]</p>

<p>[104]</p>

<p>[105]</p>

<p>[106]</p>

<p>[107]</p>

<p>[108]</p>

<p>[109]</p>

<p>[110]</p>

<p>[111]</p>

<p>[112]</p>

<p>[113]</p>

<p>[114]</p>

<p>[115]</p>

<p>[116]</p>

      <h5>3.3.7  Predicting rank order and pairwise preferences</h5>

<p>[117]</p>

<p>[118]</p>

<p>[119]</p>

<p>[120]</p>
      
      <h5>3.3.8  Learning from speech quality prediction in other domains</h5>

<p>[121]</p>

<p>[122]</p>

<p>[123]</p>

<p>[124]</p>

<p>[125]</p>      
      
  <h3>4. The VoiceMOS Challenge 2022</h3>

<p>[126]</p>

    <h4>4.1  Data and tracks</h4>

<p>[127]</p>

<p>[128]</p>

<p>[129]</p>

<p>[130]</p>

<p>[131]</p>

<p>[132]</p>

    <h4>4.2  Baselines</h4>
    
    <h4>4.3  Team approaches</h4>

<p>[133]</p>

<p>[134]</p>

<p>[135]</p>

<p>[136]</p>

<p>[137]</p>

<p>[138]</p>

<p>[139]</p>

<p>[140]</p>

<p>[141]</p>

<p>[142]</p>

<p>[143]</p>
    
  <h3>5. The VoiceMOS Challenge 2023</h3>

<p>[144]</p>

    <h4>5.1  Data and tracks</h4>

<p>[145]</p>

<p>[146]</p>

<p>[147]</p>

    <h4>5.2  Baselines</h4>

    <h4>5.3  Team approaches</h4>

<p>[148]</p>

<p>[149]</p>

<p>[150]</p>
    
  <h3>6.  Future prospects and challenges</h3>

<p>[151]</p>

<p>[152]</p>







